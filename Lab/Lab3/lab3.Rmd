---
title: "Lab 3:  Identifiability & the Simple Substitution Estimator"
subtitle: "WCM Modern Methods for Causal Inference"
date: "Due on Canvas by Wednesday, June 3, 2020 at 11:59 PM"
output: 
  wcmtheme::wcm_html: 
    toc: true
    toc_float: true
    number_toc: true
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

> Review the  steps 1-5 of the roadmap; obtain the value the statistical estimand closed form; Obtain the value the statistical estimand with simulations; Introduce and implement the simple substitution estimator based on the G-Computation formula; Use simulations to evaluate the properties of estimators. 

# Background Story üèπ

*"The Hunger Games is written in the voice of sixteen-year-old Katniss Everdeen, who lives in a post-apocalyptic world in the country of Panem where the countries of North America once existed. The Capitol, a highly advanced metropolis, holds hegemony over the rest of the nation. The Hunger Games are an annual event in which one boy and one girl aged 12 to 18 from each of the 12 districts surrounding the Capitol are selected by lottery as 'tributes' to compete in a televised battle in which only one person can survive."*  --Wikipedia, "The Hunger Games"

Some of the tributes have trained extensively for this tournament. The life experiences of other tributes have resulted in certain abilities/advantages (e.g. strength, tree climbing, markmanship). Prior to the tournament, a committee of judges assigns a score to each the tribute indicating his/her probability of winning. Once the tournament starts, forming alliances and sponsorship can aid in survival. A lone victor returns to their district and is showered with wealth and other resources. 

Suppose we are interested in the effect of forming an alliance on the probability of surviving through the first 24 hours. We have randomly sampled one tribute from each year of the games. Let $W_1$ denote the tribute's sex with $W_1=1$ being male and $W_1=0$ female. Let $W_2$ denote the score from the judges. Let $A$ be an indicator that an alliance is formed, and  $Y$ be an indicator of survival through the first 24 hours.  Finally, let $W_3$ be an indicator of whether the tribute receives aid from sponsors during the tournament. Our goal is to evaluate the effect of forming an alliance on the probability of surviving through the first 24 hours. 

This study can be translated into the following directed acyclic graph (DAG) shown in Figure 1.

![Figure 1. Hunger Games Directed Acyclic Graph (DAG)](DAG.png)

1. **Translate the DAG into the corresponding structural causal model.**

2. **Are there any exclusion restrictions or independence assumptions?**

3. **Specify the causal question and parameter.**

# Causal Parameters to Statistical Estimands

4. **Suppose the observed data consist of $n$ independent, identically distributed (i.i.d.) draws of the random variable  $O=(W_1, W_2, A, Y, W_3) \sim \mathrm{P}$. Explain the link between the SCM and the observed data. Does the structural causal model place any restrictions on the statistical model?**

5. **Explain the goal of identification. Briefly list and explain the three main assumptions we discussed in class to help us identify a causal parameter.**

6. **Assess identifiability of your causal parameter $\theta^*$. If not identified, under what assumptions would it be?**

7. **Write out the target statistical estimand in terms of the observed data distribution $\theta$.**

# A specific Data Generating Process (DGP)

The above SCM is  compatible with many possible data generating processes. Recall the SCM is a causal model for the set of possible distributions $\mathrm{P}$ for $(U,X)$. Now, consider the a specific data generating process, where each of the exogenous nodes $U_{X_i}$ is drawn independently from the following   distributions.
\begin{align*}
U_{W_1}&\sim Uniform(0,1) \\
U_{W_2}& \sim Normal(\mu=1, \sigma^2=2^2)\\
U_{A} &\sim Uniform(0,1)\\
U_{Y} &\sim Uniform(0,1)\\
U_{W_3}& \sim Uniform(0,1)
\end{align*}
Given the $U$s, the endogenous variables are deterministially generated as:
 \begin{align*}
W_1& \leftarrow \mathrm{I}\big[ U_{W_1}<0.45 \big]\\
W_2& \leftarrow 0.75^*U_{W_2}\\
A& \leftarrow \mathrm{I}\big[ U_A < \mathrm{expit}(-1+2.6^*W_1+0.9^*W_2) \big]\\
Y& \leftarrow \mathrm{I}\big[ U_Y < \mathrm{expit}(-2+A+0.7^*W_1) \big] \\
W_3& \leftarrow  \mathrm{I}\big[ U_{W_3} <\mathrm{expit}(-1+1.3^*A+2.9^*Y) \big]
\end{align*}
The $\mathrm{expit}$ function is the inverse of the logistic function: \begin{align*}
logit(x) = log\left(\frac{x}{1-x} \right) \quad \text{ and } \quad \mathrm{expit}(x) =\frac{1}{1+e^{-x}}
 \end{align*}

8. **Evaluate $\theta$ in closed form for this particular DGP.**

9. **Interpret $\theta$.**

10. **Translate the DGP into simulations.**
  a. **Set the seed to 343.**
  b. **Set the number of draws $n<-5000$.**
  c. **Sample $n$ i.i.d. observations of random variable $O=(W_1, W_2, A,Y, W_3) \sim \mathrm{P}$.**  In other words, simulate the background factors $U$ and evaluate the structural equations $F$. The $\mathrm{expit}$ function in `R` is `plogis`.
  d. **Create a data frame to hold these values.** The rows are the $n$ repetitions of the data generating process and the columns are the random variables. In other words, the rows are the $n$ subjects and the columns are their characteristics. **Use the `head` and `summary` functions to get a better understanding of the data generating process.**

# Simple substitution estimator based on the G-Computation formula

Until now, we have used our knowledge of the true distribution of the observed data $\mathrm{P}$ to obtain the value of the target parameter. Specifically, we plugged in the true conditional mean $\mathrm{E}(Y|A,W)$ and the marginal distribution $\mathrm{P}(W)$ into the G-computation formula:

$$\theta= \mathrm{E}  [\mathrm{E}(Y|A=1, W) - \mathrm{E}(Y|A=0,W)]$$

where $W$ represents the covariates that satisfy the back-door criterion for the effect of $A$ on $Y$.

In reality, we usually do not know the true distribution of the observed data $\mathrm{P}$. Instead, we only have a sample of $n$ i.i.d. observations of $O$ from $\mathrm{P}$. An intuitive estimator of the statistical estimand $\theta$  is the simple substitution estimator based on the G-Computation formula. Briefly, the algorithm estimates the relevant parts of the observed data distribution $\mathrm{P}$ and plugs them into the  parameter mapping $\theta$:

*Step 1: Estimate the conditional mean $\mathrm{E}(Y|A,W)$ using the observed data as input.*

*Step 2: Estimate the marginal distribution of baseline covariates $\mathrm{P}(W)$ using the observed data as input.*

*Step 3: Substitute these estimates into the target parameter mapping: \[\hat{\theta} = \sum_{W_1} \big[ \hat{\mathrm{E}}(Y|A=1, W=w ) - \hat{\mathrm{E}}(Y|A=0,W=w) \big]\hat{\mathrm{P}}(W=w)\]*

Formally, an estimator $\hat{\theta}$ is a mapping from the set of possible empirical distributions of $\mathrm{P}$ to the parameter space ($\mathbb{R}$). In other words, $\hat{\theta}$ is a function with input as the observed data and output a value in the parameter space (e.g. a number).  The estimator should respect the statistical model, which is non-parametric. In other words, we should not make any unfounded assumptions about the observed data distribution $\mathrm{P}$.

## Implementation with the NPMLE

11. **Complete *Step 1* by estimating the conditional mean function with the non-parametric maximum likelihood estimator (NPMLE). Create strata of each possible value of $(A,W_1)$ and take the empirical mean of $Y$ in each strata.** This is equivalent to fitting a saturated regression model.

    *Hint:* The following code creates a vector of the outcomes among unexposed ($A=0$) females ($W_1=0$). The NPMLE for the conditional probability of survival for this subgroup is the empirical mean of the resulting vector:
    
    ```{r, echo=T, eval=F}
    #outcomes among unexposed females
    Y_a0w0<-  Y[W_1==0 & A==0]
    meanY_a0w0 <- mean(Y_a0w0)
    meanY_a0w0
    ```

12. **Complete *Step 2* by estimating the marginal distribution $\mathrm{P}_0(W_1=w_1)$ with the sample proportion:**
$$\hat{\mathrm{P}}(W_1=w_1) = \frac{1}{n} \sum_{i=1}^n \mathrm{I}(W_{1_i} = w_1)$$

    Again, this non-parametric estimator does not place any restrictions on the statistical model.

13. **Substitute these estimates into the parameter mapping to complete *Step 3***.

$$ \hat{\theta} =  \big[ \hat{\mathrm{E}}(Y|A=1, W_1=1 ) - \hat{\mathrm{E}}(Y|A=0,W_1=1) \big]\hat{\mathrm{P}}(W_1=1) $$
  $$ + \big[ \hat{\mathrm{E}}(Y|A=1, W_1=0 ) - \hat{\mathrm{E}}(Y|A=0,W_1=0) \big]\hat{\mathrm{P}}(W_1=0) $$


## Implementation with a "saturated" parametric regression

In the previous section, we estimated the conditional risk $\mathrm{E}(Y|A,W_1)$ with the empirical mean outcome $Y$ in strata of $A$ and $W_1$. This is equivalent to fitting a saturated parametric model for the conditional mean: \[
\mathrm{E}_(Y|A,W_1)= \mathrm{P}(Y=1|A,W_1) = \mathrm{expit}\big( \beta_0 + \beta_1 A + \beta_2 W_1 + \beta_3 A\times W_1\big)
\]

14. **Use the `glm` function to fit the conditional mean function $\mathrm{E}(Y|A,W_1)$ with logistic regression to complete *Step 1*.**

15. **To implement *Step 2*:**

    **a. Copy the  data set `Obs` into two new data frames `trt` and `control`.  Then set `A=1` for all units in `trt` and `A=0` for all units in `control`.**

    **b. Now use the `predict` function to get the expected outcomes for each individual $i$ under the intervention $\hat{\mathrm{E}}(Y_i|A_i=1, W_{1_i})$. Be sure to specify the arguments `newdata=trt` and the `type='response'`.**

    **c. Again use the `predict` function to get the expected outcomes for each individual $i$ under the control  $\hat{\mathrm{E}}(Y_i|A_i=0, W_{1_i})$.**

16. **For *Step 3*, evaluate the statistical parameter by substituting the predicted mean outcomes under the treatment and under the control into the G-Computation formula.** The sample proportion is a non-parametric maximum likelihood estimator of  the marginal distribution of $W_1$.  So we can just take the empirical mean of the difference in the predicted outcomes for each subject:
\[ \hat{\theta} = \frac{1}{n} \sum_{i=1}^n \bigg[ \hat{\mathrm{E}}(Y_i|A_i=1, W_{1_i}) - \hat{\mathrm{E}}(Y_i|A_i=0, W_{1_i})\bigg] \]


## Estimate the bias, variance and mean squared error (MSE) of the  substitution estimator.

Simulations are useful for evaluating the properties of estimators. We will focus on estimating the bias, variance and mean squared error of the simple substitution estimator. Specifically, for $R=500$ iterations, we will sample $n=200$ i.i.d. observations from $\mathrm{P}$, implement the simple substitution estimator based on the G-Computation formula, and save the resulting vector of $\hat{\theta}$s.

17. **Set `R` to 500 and `n` to 200, and then create a vector `estimates` of length $R=500$ to hold the estimated value of $\theta$ obtained  at each iteration.**

18. **Inside a `for` loop from 1 to $R=500$, sample $n$ i.i.d. observations of random variable $O = (W_1,W_2,A,Y,W_3)$; implement the simple substitution estimator using the saturated regression model (adjusting for $A$, $W_1$ and their interaction), and save the resulting estimate $\hat{\theta}$ as an entry in the vector `estimates`.**

19. **What is the average value of the estimates of $R=500$ simulations?**

20. **Estimate the bias of the estimator. What is the average deviation of the estimate and the truth $\theta$?**  \[
Bias\big(\hat{\theta} \big) = \mathrm{E}( \hat{\theta} - \theta ) \]

21. **Estimate the variance of the estimator.** How much do the estimates vary across samples?

\[
Variance\big(\hat{\theta} \big) = \mathrm{E}\left( \bigg(\hat{\theta} - \mathrm{E}[\hat{\theta} ] \bigg)^2\right) \]

25. **Estimate the mean squared error of the estimator.** On average, how far are the estimates from the truth? $$
MSE\big(\hat{\theta} \big) = \mathrm{E}\left( \bigg(\hat{\theta} - \theta \bigg)^2\right)\\
= Bias^2 + Variance $$
