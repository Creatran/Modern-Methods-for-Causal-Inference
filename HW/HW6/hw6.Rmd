---
title: "HW 6: Simple implementation of TMLE"
subtitle: "Modern Methods for Causal Inference"
date: "Due July 13, 2020 at 3pm on Canvas"
output: 
  wcmtheme::wcm_html: 
    toc: true
    toc_float: true
    number_toc: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This homework will cover Targeted Minimum Loss-Based Estimation (TMLE) using *parametric* models (generalized linear models, as opposed to data adaptive methods). Next class you will begin implementing TMLE using data adaptive methods via SuperLearner.

Although we do not have a practice lab for this homework, you can [review a similar TMLE tutorial here](https://migariane.github.io/TMLE.nb.html#1_introduction).

# Background

Suppose you want to study the effect of steroid administration on critically ill COVID-19 patients. You will collect data on the following variables:

- `Y`: a 28 day mortality indicator

- `A`: binary treatment variable for steroids on first day of hypoxic state (hypoxic state defined as requiring greater than 6L of supplemental oxygen) (1: yes 0: no)

- `W1`: Gender (1 male; 0 female)

- `W2`: Age at hospitalization (in decades)

- `W3`: SOFA pulmonary organ failure score (scale of increasing severity from 1 to 4)

- `W4`: Number of relevant comorbidities (scale from 1 to 5) - Coronary Artery Disease, hypertension, Diabetes Mellitus, asthma, immunosuppressed state 

**1. Set your seed to 7 and run the following data generating function to simulate `n=10,000` COVID-19 patients.**

```{r, eval=F}
generateData <- function(n){
  w1 <- rbinom(n, size=1, prob=0.35)
  w2 <- rnorm(n, mean = 6, sd = 1)
  w3 <- round(runif(n, min=0, max=4), digits=3)
  w4 <- round(runif(n, min=0, max=5), digits=3)
  A  <- rbinom(n, size=1, prob= plogis(-0.8 + 0.3*w2 + 0.25*w3 + 0.2*w4 + 0.3*w2*w4))
  # counterfactual
  Y_1 <- rbinom(n, size=1, prob= plogis(-3 + 1 -0.2*w1 + 0.35*w2 + 0.15*w3 + 0.25*w4 + 0.1*w2*w4))
  Y_0 <- rbinom(n, size=1, prob= plogis(-3 + 0 -0.2*w1 + 0.35*w2 + 0.15*w3 + 0.25*w4 + 0.1*w2*w4))
  # Observed outcome
  Y <- Y_1*A + Y_0*(1 - A)
  # return data.frame
  data.frame(w1, w2, w3, w4, A, Y, Y_1, Y_0)
}
```

**2. Calculate *and interpret* the true value of $\theta = E[Y_1]-E[Y_0]$.**

# Simple TMLE Implementation

## Step 1: Estimate $m(A,W)$

Estimation of the initial probability of the outcome ($Y$) given the treatment ($A$) and the set of covariates ($W$), denoted as $m(A,W)$. To estimate $m(A,W)$ we can use a standard logistic regression model:

$m(A,W) = logit[P(Y=1|A,W)]=β0+β1A+β_2^TW$

**3. Fit the above `glm` and use the `predict` function to obtain the outputs of $m(A,W)$, $m(1,W)$, and $m(0,W)$.**

**4. If you were to stop here and estimate the casual parameter $\theta = E[Y_1]-E[Y_0]$ using $\hat{\theta} = \hat{m}(1,W)-\hat{m}(0,W)$, what statistical estimation technique would this be? Implement this estimation technique for comparison with TMLE.**

## Step 2: Estimate $g(W)$

Next we need of the probability of the treatment ($A$) given the set of covariates ($W$), denoted as $g(W)$. We can again use a logistic regression model for this simple implementation.

$g(W) = logit[P(A=1|W)]=\alpha_0+\alpha_1^TW$

**5. Fit the above `glm` and use the `predict` function to obtain the outputs of $g(W)$. Compute $P(A=1|W)$ and $P(A=0|W)$ for every patient in the simulated study and call these vectors `prob_A1_given_W` and `prob_A0_given_W`.**

**6. Comment on the distributions of $\hat{g}(W)$ and $1-\hat{g}(W)$.**

## Step 3: Estimate the clever covariate $H(A,W)$

**7. Use these estimates to create the clever covariate `H_AW`. Interpret the clever covariate for this particular background story.**

\[
\hat{H}(A,W) = \left(\frac{\mathrm{I}(A=1)}{\hat{g}(W)} - \frac{\mathrm{I}(A=0)}{1-\hat{g}(W)}  \right)
\]

**8. Also evaluate the clever covariate at $A=1$ and $A=0$ for all patients. Call the resulting vectors `H_1W` and `H_0W`, respectively.**

**9. What previously learned causal inference statistical estimation technique do you now have all the necessary information to complete? Implement this technique for comparison with TMLE.**

## Step 4: Target the initial estimator

*This is the crucial step of TMLE: updating the initial estimator of the conditional mean outcome $\hat{\mathrm{E}}(Y|A,W)$ with information in the estimated exposure mechanism $\hat{\mathrm{P}}(A=1|W)$.*

**10. Run a univariate regression of the outcome $Y$ on the clever covariate $\hat{H}(A,W)$ with the (logit of the) initial estimates as offset. Specifically, we estimate the coefficient $\epsilon$ by fitting the following logistic regression model:**
\begin{align*}
logit[m(A,W;\epsilon)] = logit[\hat{m}(A,W)] + \epsilon \hat{H}(A,W).
\end{align*}

*Note:* there is no intercept (i.e. there is no $\beta_0$ term), and the coefficient on the ($logit$ of the) initial estimator is set to 1.

```{r, eval=F}
logit_update<- glm(ObsData$Y ~ -1 + offset(qlogis(expY_givenAW)) + H_AW,
                  family='binomial')
```

**11. Let `epsilon` denote the resulting maximum likelihood estimate of the coefficient on the clever covariate `H_AW`.**

**12. Update the initial estimate of $\hat{m}(A,W)$ according to the fluctuation model:**

\begin{align*}
logit[\hat{m}(A,W)] &= logit [\hat{m}(A,W)] + \hat{\epsilon} \hat{H}(A,W) \\
\tilde{m}(A,W) &=  expit \bigg[ logit\big[ \hat{m}(A,W) \big] + \hat{\epsilon} \hat{H}(A,W) \bigg]
\end{align*}

**13.  Plug-in the estimated coefficient $\hat{\epsilon}$ to yield targeted estimates of the expected outcome under the exposure $\tilde{m}(1,W)$ and under no exposure $\tilde{m}(0,W)$:**

\begin{align*}
\tilde{m}(1,W) &= expit \bigg[ logit\big[ \hat{m}(1,W) \big] + \hat{\epsilon} \hat{H}(1,W) \bigg]\\
\tilde{m}(0,W) &= expit \bigg[ logit\big[ \hat{m}(0,W) \big] + \hat{\epsilon} \hat{H}(0,W) \bigg]\\
\end{align*}

Recall $\hat{H}(1,W)$ is the clever covariate evaluated for all units under the exposure, and $\hat{H}(0,W)$ is the clever covariate evaluated for all units under no exposure.

**14. Estimate and interpret $\theta = E[Y_1]-E[Y_0]$ using TMLE. Compare it with the true value, and your estimates in the previous questions.**

# Inference

**15. How can we obtain standard errors for TMLE? How does this compare to G-Computation, IPTW, and Augmented IPTW?**

**16. What limitations do you see in estimating $g(W)$ and $m(A,W)$ using logistic regressions?**
