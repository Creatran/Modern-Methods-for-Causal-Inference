A roadmap for causal inference

## Step 0: Specify the scientific question

## Step 1: Specify the Causal Model

### Structural Causal Model (SCM)

* Endogenous variables: X = {X1, ..., Xj}
* Background (exogenous) variables: U = {Ux1, ..., Uxj} ~ P*
* Structural equations: F = {fx1, ..., fxj}; Xj <- fxj(Pa(Xj), Uxj)

### SCM encode causal assumptions

* Exclusion restrictions: restrictions on the parents of X (exclusding a variable from Pa(Xj) assumes it does not directly affect the value Xj takes)
* Independnece assumptions: assumptions on the independence of any two+ U variables

## Step 2: Specify the causal parameter 

### Counterfactuals

Intervention variable: A; outcome: Y;

intervention: Intervene on the system to set A <- 1

Interventions generate counterfactuals:

Ya: the value that variable Y would have taken if that individual had received treatment (exposure) A = a. 

Intervention 1: All women take vitamins

Intervention 2: No woman takes vitamins

Y1: counterfactual breast cancer status for a woman if possibly contrary-to-fact she took vitamins A = 1

Y0: counterfactual breast cancer status for a woman if possibly contrary-to-fact she did not take vitamins A=0 

* The counterfactuals are uniquely determined by U and F. Thus, the distribution of U implies the distribution of the counterfactuals. (Y1, Y0) ~ P*.

### Defining a target causal parameter

* ATE (average treatment effect): $\theta^* = E^*[Y1] - E^*[Y0]$ 
* Effect within certain strata: $\theta^* = E^*[Y1 - Y0 | V], V \in W$
* Causal risk difference: $\theta = P^*(Y1 = 1) - P^*(Y0 = 1)$ 
* Causal relative risk: $\frac{P^*(Y_1 = 1)}{P^*(Y_0 = 1)}$ 
* Causal odds ratio: $\frac{P^*(Y1 = 1)/(1 - P^*(Y1 = 1))}{P^*(Y0 = 1)/(1 - P^*(Y0 = 1))}$ 
* MArginal structural models (MSMs): useful when the treatment A or conditioning strata V have many possible levels. $E^*(Y_a) = m(a|\beta) = \beta_0 \beta_1a$

## Step 3: Specify the observed data & its link to the causal model 

### Specify the observed data

O = (W, A, Y) ~ P

This is a statistics and does not use the causal model (yet).

### Linking the observed data to the causal model

U and F determines O (some testable implications of SCM)

We observe a sample of size n of random variable O This gives us n independent identically distribution (i.i.d.) copies of O1 , O2 , . . . , On drawn from probability distribution P;

We assume our observed data were generated by sampling n from a system compatible with (described by) our structural causal model;

Any data generating experiment that is compatible with our causal model will give rise to an observed data distribution in which A and Y are independent.

The causal model implies a statistical model (which gives us the set of allowed distributions for O)

* When is a path blocked?

  If the path has a non-collider that has been conditioned on 

  OR if it has a collider and neither the collider not its descendent have been conditioned on

* D-separation

  If a set of variables S blocks all paths from X to Y, then S d-separates X and Y, and X is independent of Y given S: S d-separates X and Y = X and Y are independent conditional on S.

  But, if A and Y are not d-separated by W, then A and Y could be independent given W

* The statistical model: the set of possible distributions for the observed data

  * Non-parametric statistical model: no restrictions on the set of possible observed data distributions
  * Semi-parametric statistical model: some restrictions on the set of possible observed data distributions
  * Parametric statistical model: assumes P is known up to a ﬁnite number of unknown parameters

## Step 4: Identify: Knowledge + data sufﬁcient?

The task of identiﬁability is to write a parameter θ* of the distribution of the counterfactuals as a parameter θ of the distribution of the observed data.

Main assumption: $Y_a {\perp \!\!\! \perp} A | W$ , called ignorability, exchangeability, or randomization assumption.

Under ignorability: $E^*(Y_a|W = w) = E(Y|A = a, W = w)$ , $E[Y_a] = E[E(Y|A = a, W)]$  

 $Y_a {\perp \!\!\! \perp} A$ , holds under:

* Randomization assumption: $U_Y {\perp \!\!\! \perp} U_A$ 
* Back-door criterion:
  * No node in W is a descendant of A
  * W blocks all “back-door" paths from A to Y

$E^*(Y_a|W = w) = E(Y|A = a, W = w)$ 

* G-computation formula:

   $\theta^* = E^*(Y_a) = \sum_wE(Y|A = a, W  =w)P(W = w) = \theta = E[E(Y|A = a, W)]$   

* Positivity assumption:

  $min_{a \in A}P_0(A = a|W = w) > 0$ for all w for which P(W = w) > 0

##  Step 5 Commit to an estimand as close to question as possible, and a statistical model representing real knowledge 



## Step 6: Estimate

### Implementing a substitution estimator 

Plugging an estimates of the relevant pieces of the observed data distribution (P(W ) and E[Y|A, W ]) into the parameter mapping θ : $\theta(\hat{p}) = \frac{1}{n}\sum_{i = 1}^n[E_n(Y_i|A_i = 1, W_i) - E_n(Y_i|A_i = 0, W_i)]$ 

### On multivariate linear regression adjustment

$E_n(Y|A, W) = \hat{\beta_0} + \hat{\beta_1} A + \hat{\beta_2}W$ 

$\hat{\theta} = \frac{1}{n}\sum_{i = 1}^n[E_n(Y_i|A_i = 1, W_i) - E_n(Y_i|A_i = 0, W_i)] = \hat{\beta_1}$ 

### On logistic regression adjustment

* Marginal average treatment effect:

  θ = E[E(Y |A = 1, W) − E(Y |A = 0, W)]

* Conditional treatment effect:

  θ(w) = E(Y |A = 1, W = w) − E(Y |A = 0, W = w)

### Inverse Probability of Treatment Weighting (IPTW) Estimator

* G-comp. and IPTW estimands are equivalent :

  $E^*[Y_a] = E[Y|A = a] = E[E(Y | A = a, W)] = E[\frac{I(A = a)}{P(A = a | W )}Y]$ 

* IPTW estimand suggests a new estimator:

  $IPW = \frac{1}{n}\sum_{i = 1}^n\frac{I(A_i = a)}{P(A_i = a|W_i)}Y_i$ (Standard IPTW estimator)

  $\hat{we_i} = \frac{I(A_i = a)}{\hat{P}(A_i = a|W_i)}$ 

* IPTW & Trunction of the Weights

  Consistency of IPTW relies on having a consistent estimator of P(A | W )

  By enforcing arbitrary bounds on the predicted probabilities, we are ensuring that our estimator of P(A|W ) is not consistent:

  - Resulting IPTW estimator will be biased

  - Intuition: No longer adjusting completely for measured covariates

* An alternative IPTW estimator

  $E[\frac{I(A = a)}{P(A | W )}Y] = \frac{E[\frac{I(A = a)}{P(A | W )}Y]}{E[\frac{I(A = a)}{P(A | W )}]}$ 

  stabilized IPTW estimator: $\frac{\frac{1}{n}\sum_{i = 1}^n\frac{I(A_i = a)}{P(A_i = a|W_i)}Y_i}{\frac{1}{n}\sum_{i = 1}^n\frac{I(A_i = a)}{P(A_i = a|W_i)}} = \sum_{i = 1}^n\frac{\frac{I(A_i = a)}{P(A_i = a|W_i)}}{{\sum_{i = 1}^n\frac{I(A_i = a)}{P(A_i = a|W_i)}}}Y_i = \sum_{i = 1}^n\hat{we_i}Y_i$ 

  stabilized weights: $\frac{\hat{P(A)}}{\hat{p}(A_i|W_i)}$  

### Marginal Structural Models

$E^*[Y_a] = m(\alpha|\beta) = \beta_0 + \beta_1\alpha$ 

### Data-Adaptive Estimation

* Estimation with a misspecified parametric regression
  * Biases point estimates
  * Misleading statistical inference
  * Misleading conclusions
* Estimation respecting the non-parametric statistical model
  * Number of parameters  grouws exponentially with dimension of (A, W) - over-fit (curse of dimensionality)
  * Do not make any a priori assumptions
* Dangers of looking at the data in ad hoc way
  * Bias
  * Misleading assessment of uncertainty
* We need to look at the data in a rigorous (supervised) way

Wrong bias-variance trade-off: force Super Learner to keep the exposure A

### Augmented IPW and TMLE (Doubly-robust)

use ML to solve model misspecification bias, while still allowing computation of CIs and p-values

$P(O) = P(W, A, Y) = P(W) P(A|W)P(Y|A, W)$ 

$m(W) = E[Y|A = 1, W]$

$g(W) = P(A = 1|W)$ 

* $\theta = E[E(Y|A = 1, W)] = E[m(W)] = E[\frac{A}{g(W)}Y]$ 
* G-computation (a.k.a substitution estimator) $\hat{\theta}_{sub} = \frac{1}{n}\sum_{i = 1}^n\hat{m}(W_i)$ 
* IPW estimator: $\hat{\theta}_{ipw} = \frac{1}{n}\sum_{i = 1}^n\frac{A_i}{\hat{g}(W_i)}Y_i$ 
* AIPW: $\hat{\theta}_{aipw} = \frac{1}{n}\sum_{i = 1}^n\{\frac{A_i}{\hat{g}(W_i)}[Y_i - \hat{m}(W_i)] + \hat{m}(W_i)\}$ 
  * estimate toe asymptotic variance: $\sigma^2 = Var\{D_P(O)\}$ , $D_P(O_i) = \frac{A_i}{\hat{g}(W_i)}[Y_i - \hat{m}(W_i)] + \hat{m}(W_i) - \hat{\theta}_{aipw}$ 
  * 95% CI: $\hat{\theta}_{aipw} +/- 1.96 \hat{\sigma}/\sqrt{n}$ 
  * H0: $\theta = 0$ : $\hat{\theta}_{aipw} \sim N(0, \hat{\sigma}^2/n)$ 
* TMLE: $\hat{\theta}_{tmle} = \frac{1}{n}\sum_{i = 1}^n\tilde{m}(W_i)$ , where $\frac{1}{n}\sum_{i = 1}^n\frac{A_i}{\hat{g}(W_i)}[Y_i - \hat{m}(W_i)] = 0$ 
  * Estimate m(W) = E[Y|A = 1, W]
  * $\hat{H}(W_i) = \frac{1}{\hat{g}(W_i)}$ 
  * 

## Step 7: Interpret results



## Notes

What is required for causal inference?

Causal inference requires untestable assumptions

What is special about causal inference?

Data + statistical assumptions = statistical inference.

- Conclusions about an underlying population,

- E.g., can we predict who will develop cancer?

Data + statistical assumptions + causal assumptions (non testable) = causal inference

- Conclusions about how the underlying population would change if conditions changed 
- E.g., do we know how to reduce the risk of cancer?



* 

Identifiability

* What we want: The expectation of E ∗ (Y 1 − Y 0 )

* What we have: An i.i.d sample (W 1 , A 1 , Y 1 ), . . . , (W n , A n , Y n ), which allow us to learn about the distribution P of (W , A, Y )

* Identiﬁability is the process of linking the distribution of the counterfactuals (Y 1 , Y 0 ) (unobserved) to the distribution of (W , A, Y ) (observed)



